{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GqwapXuoUKP",
    "outputId": "81586bf7-b534-40e3-ef21-885858236dd9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUQHQQX_WLm5",
    "outputId": "9448dfe4-f15f-4486-cb39-86cc9d176adf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting lancedb\n",
      "  Downloading lancedb-0.15.0-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting vllm\n",
      "  Downloading vllm-0.6.3.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (10 kB)\n",
      "Collecting deprecation (from lancedb)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pylance==0.19.1 (from lancedb)\n",
      "  Downloading pylance-0.19.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from lancedb) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from lancedb) (4.66.6)\n",
      "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from lancedb) (2.9.2)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from lancedb) (24.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lancedb) (24.1)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from lancedb) (5.5.0)\n",
      "Collecting overrides>=0.7 (from lancedb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance==0.19.1->lancedb) (17.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22 in /usr/local/lib/python3.10/dist-packages (from pylance==0.19.1->lancedb) (1.26.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n",
      "Collecting transformers>=4.45.2 (from vllm)\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.1/44.1 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.19.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (3.20.3)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.10.10)\n",
      "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.52.2)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting lm-format-enforcer==0.10.6 (from vllm)\n",
      "  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting outlines<0.1,>=0.0.43 (from vllm)\n",
      "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.16.1)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Downloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n",
      "Collecting msgspec (from vllm)\n",
      "  Downloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf==0.10.0 (from vllm)\n",
      "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.5.0)\n",
      "Collecting mistral-common>=1.4.4 (from mistral-common[opencv]>=1.4.4->vllm)\n",
      "  Downloading mistral_common-1.4.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n",
      "Collecting compressed-tensors==0.6.0 (from vllm)\n",
      "  Downloading compressed_tensors-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Downloading ray-2.38.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch==2.4.0 (from vllm)\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.19 (from vllm)\n",
      "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting xformers==0.0.27.post2 (from vllm)\n",
      "  Downloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0 (from vllm)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->vllm)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0->vllm)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm) (12.6.77)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (4.23.0)\n",
      "Collecting tiktoken>=0.6.0 (from vllm)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.4.4->vllm) (4.10.0.84)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.3.1)\n",
      "Collecting lark (from outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
      "Collecting diskcache (from outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n",
      "Collecting datasets (from outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pycountry (from outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyairports (from outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->lancedb) (2.23.4)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.1.0)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->lancedb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->lancedb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->lancedb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->lancedb) (2024.8.30)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.9.11)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.24.7)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.2->vllm) (0.4.5)\n",
      "Collecting tokenizers>=0.19.1 (from vllm)\n",
      "  Downloading tokenizers-0.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.20.2)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm) (1.0.6)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (0.20.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->vllm) (0.2.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n",
      "Collecting xxhash (from datasets->outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->outlines<0.1,>=0.0.43->vllm)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.4.0->vllm)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->vllm) (3.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.16.0)\n",
      "Downloading lancedb-0.15.0-cp38-abi3-manylinux_2_28_x86_64.whl (27.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.1/27.1 MB\u001B[0m \u001B[31m58.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pylance-0.19.1-cp39-abi3-manylinux_2_28_x86_64.whl (30.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.4/30.4 MB\u001B[0m \u001B[31m21.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading vllm-0.6.3.post1-cp38-abi3-manylinux1_x86_64.whl (194.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.8/194.8 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading compressed_tensors-0.6.0-py3-none-any.whl (92 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.0/92.0 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m71.6/71.6 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.7/43.7 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m797.2/797.2 MB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.0/7.0 MB\u001B[0m \u001B[31m58.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.8/20.8 MB\u001B[0m \u001B[31m35.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m81.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m69.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m50.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.2/176.2 MB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m209.4/209.4 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.7/94.7 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mistral_common-1.4.4-py3-none-any.whl (6.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m109.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.9/101.9 kB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading ray-2.38.0-cp310-cp310-manylinux2014_x86_64.whl (66.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.0/66.0 MB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m66.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.0/10.0 MB\u001B[0m \u001B[31m114.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tokenizers-0.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m99.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m210.3/210.3 kB\u001B[0m \u001B[31m20.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.5/40.5 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading partial_json_parser-0.2.1.1.post4-py3-none-any.whl (9.9 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m442.1/442.1 kB\u001B[0m \u001B[31m34.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.3/73.3 kB\u001B[0m \u001B[31m7.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/3.8 MB\u001B[0m \u001B[31m101.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m425.7/425.7 kB\u001B[0m \u001B[31m36.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m164.1/164.1 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m480.6/480.6 kB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m179.3/179.3 kB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.5/45.5 kB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m111.0/111.0 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m371.7/371.7 kB\u001B[0m \u001B[31m31.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.3/6.3 MB\u001B[0m \u001B[31m109.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m63.7/63.7 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m12.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m18.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: pyairports, nvidia-ml-py, xxhash, websockets, uvloop, uvicorn, triton, python-dotenv, pycountry, partial-json-parser, overrides, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, lark, interegular, httptools, gguf, fsspec, diskcache, dill, deprecation, watchfiles, tiktoken, starlette, pylance, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, torch, tokenizers, prometheus-fastapi-instrumentator, lm-format-enforcer, lancedb, fastapi, xformers, transformers, torchvision, ray, mistral-common, datasets, compressed-tensors, outlines, vllm\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
      "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.0+cu121\n",
      "    Uninstalling torch-2.5.0+cu121:\n",
      "      Successfully uninstalled torch-2.5.0+cu121\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.0+cu121\n",
      "    Uninstalling torchvision-0.20.0+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.0+cu121\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
      "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.4.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed compressed-tensors-0.6.0 datasets-3.1.0 deprecation-2.1.0 dill-0.3.8 diskcache-5.6.3 fastapi-0.115.4 fsspec-2024.9.0 gguf-0.10.0 httptools-0.6.4 interegular-0.3.3 lancedb-0.15.0 lark-1.2.2 lm-format-enforcer-0.10.6 mistral-common-1.4.4 msgspec-0.18.6 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.560.30 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 outlines-0.0.46 overrides-7.7.0 partial-json-parser-0.2.1.1.post4 prometheus-fastapi-instrumentator-7.0.0 pyairports-2.1.1 pycountry-24.6.1 pylance-0.19.1 python-dotenv-1.0.1 ray-2.38.0 starlette-0.41.2 tiktoken-0.7.0 tokenizers-0.20.2 torch-2.4.0 torchvision-0.19.0 transformers-4.46.1 triton-3.0.0 uvicorn-0.32.0 uvloop-0.21.0 vllm-0.6.3.post1 watchfiles-0.24.0 websockets-13.1 xformers-0.0.27.post2 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lancedb vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDdN_605jF-Y",
    "outputId": "b2cce1f4-4e53-498a-e80a-90b3f6203e33"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Block 0: Mount Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTx_1NCITloH"
   },
   "outputs": [],
   "source": [
    "# Block 1: Imports\n",
    "import transformers\n",
    "import re\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "from huggingface_hub import snapshot_download\n",
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import lancedb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HJIrSQqUyxz",
    "outputId": "8a3bab90-bce8-4c59-a8f1-7a393e447e0d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model already exists at /content/drive/MyDrive/RAG-1B\n"
     ]
    }
   ],
   "source": [
    "model_name = \"PleIAs/RAG-1B\"\n",
    "local_model_path = \"/content/drive/MyDrive/RAG-1B\"\n",
    "\n",
    "if not os.path.exists(local_model_path):\n",
    "    print(f\"Downloading {model_name} to {local_model_path}...\")\n",
    "    snapshot_download(repo_id=model_name, local_dir=local_model_path,\n",
    "                      ignore_patterns=[\"*.msgpack\", \"*.h5\", \"*.ot\", \"*.feather\"])\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(f\"Model already exists at {local_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hiha9gDEXtUI"
   },
   "outputs": [],
   "source": [
    "# Database paths\n",
    "db_path = \"/content/drive/MyDrive/rag_irene/lancedb_data\"\n",
    "table_name = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw3aW6fbki_w"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "temperature = 0.7\n",
    "max_new_tokens = 3000\n",
    "top_p = 0.95\n",
    "repetition_penalty = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381,
     "referenced_widgets": [
      "74acd1ba31504731ae5243331213f143",
      "477e4aecd847459bb5c3cd8d9375eff2",
      "aa4fbb4a43f3481e81689fd268a8ce32",
      "7938db68989144c9a9c5b7a584ae5647",
      "cdc727d124a74a8189b425f66ce7d98a",
      "e766f31c12d9458bb96501c4c1ff5bfb",
      "c169237169e841d1bb58a1feb2c2ce55",
      "81f28f0a406c4cf2a801a1b8f92fa5c2",
      "e4d5ce7b5eda4445a3da4683a3081d8f",
      "3de6222b71de463283c94fdb82b5a5a0",
      "89f3fd1d549b462f94c8fb2f6060bfe4"
     ]
    },
    "id": "wQAhIqBFko9h",
    "outputId": "50461023-4dd2-4a52-fb92-997b7d0fb596"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING 11-05 13:02:55 config.py:1668] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 11-05 13:03:06 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='/content/drive/MyDrive/RAG-1B', speculative_config=None, tokenizer='/content/drive/MyDrive/RAG-1B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/content/drive/MyDrive/RAG-1B, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 11-05 13:03:08 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 11-05 13:03:08 selector.py:115] Using XFormers backend.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO 11-05 13:03:09 model_runner.py:1056] Starting to load model /content/drive/MyDrive/RAG-1B...\n",
      "INFO 11-05 13:03:09 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 11-05 13:03:09 selector.py:115] Using XFormers backend.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74acd1ba31504731ae5243331213f143"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO 11-05 13:03:49 model_runner.py:1067] Loading model weights took 2.3185 GB\n",
      "INFO 11-05 13:03:51 gpu_executor.py:122] # GPU blocks: 15123, # CPU blocks: 8192\n",
      "INFO 11-05 13:03:51 gpu_executor.py:126] Maximum concurrency for 8192 tokens per request: 29.54x\n",
      "INFO 11-05 13:03:55 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-05 13:03:55 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-05 13:04:23 model_runner.py:1523] Graph capturing finished in 29 secs.\n"
     ]
    }
   ],
   "source": [
    "# Initialize vLLM\n",
    "llm = LLM(\n",
    "    model=local_model_path,\n",
    "    max_model_len=8192,\n",
    "    dtype=\"float16\",  # Explicitly set float16 for T4 GPU compatibility\n",
    "    gpu_memory_utilization=0.8  # Added to help with memory management\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeVw0urIlg-P"
   },
   "outputs": [],
   "source": [
    "# Connect to the LanceDB database\n",
    "db = lancedb.connect(db_path)\n",
    "table = db.open_table(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RznDAPLynL3b"
   },
   "outputs": [],
   "source": [
    "# Block 4: Search Function\n",
    "def hybrid_search(text):\n",
    "    results = table.search(text, query_type=\"hybrid\").limit(4).to_pandas()\n",
    "    document = []\n",
    "\n",
    "    for _, row in results.iterrows():\n",
    "        hash_id = str(row['hash'])\n",
    "        title = row['section']\n",
    "        content = row['text']\n",
    "        document.append(f\"**{hash_id}**\\n{title}\\n{content}\")\n",
    "\n",
    "    return \"\\n\\n\".join(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Olg8AranWLO"
   },
   "outputs": [],
   "source": [
    "# Block 5: Reference Formatting Function\n",
    "def format_references(text):\n",
    "    ref_start_marker = '<ref text=\"'\n",
    "    ref_end_marker = '</ref>'\n",
    "    parts = []\n",
    "    current_pos = 0\n",
    "    ref_number = 1\n",
    "\n",
    "    while True:\n",
    "        start_pos = text.find(ref_start_marker, current_pos)\n",
    "        if start_pos == -1:\n",
    "            parts.append(text[current_pos:])\n",
    "            break\n",
    "\n",
    "        parts.append(text[current_pos:start_pos])\n",
    "        end_pos = text.find('\">', start_pos)\n",
    "        if end_pos == -1:\n",
    "            break\n",
    "\n",
    "        ref_text = text[start_pos + len(ref_start_marker):end_pos].replace('\\n', ' ').strip()\n",
    "        ref_text_encoded = ref_text.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "        ref_end_pos = text.find(ref_end_marker, end_pos)\n",
    "\n",
    "        if ref_end_pos == -1:\n",
    "            break\n",
    "\n",
    "        ref_id = text[end_pos + 2:ref_end_pos].strip()\n",
    "        tooltip_html = f'<span class=\"tooltip\" data-refid=\"{ref_id}\" data-text=\"{ref_id}: {ref_text_encoded}\"><a href=\"#{ref_id}\">[{ref_number}]</a></span>'\n",
    "\n",
    "        parts.append(tooltip_html)\n",
    "        current_pos = ref_end_pos + len(ref_end_marker)\n",
    "        ref_number += 1\n",
    "\n",
    "    return ''.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ww6tMKQ3nm17"
   },
   "outputs": [],
   "source": [
    "# Block 6: Main Prediction Function\n",
    "def predict(user_message):\n",
    "    # Get relevant documents\n",
    "    sources = hybrid_search(user_message)\n",
    "\n",
    "    # Setup sampling parameters\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_new_tokens,\n",
    "        presence_penalty=repetition_penalty,\n",
    "        stop=[\"#END#\"]\n",
    "    )\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"### Query ###\\n{user_message}\\n\\n### Source ###\\n{sources}\\n\\n### Analysis ###\\n\"\"\"\n",
    "\n",
    "    # Generate response\n",
    "    outputs = llm.generate([prompt], sampling_params, use_tqdm=False)\n",
    "    generated_text = outputs[0].outputs[0].text\n",
    "\n",
    "    # Format response with references\n",
    "    formatted_response = format_references(generated_text)\n",
    "\n",
    "    return {\n",
    "        \"query\": user_message,\n",
    "        \"sources\": sources,\n",
    "        \"response\": formatted_response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpYJXkIMoJP3",
    "outputId": "59004af8-3c6c-4cd8-ab7f-f762a73df6d4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tantivy\n",
      "  Downloading tantivy-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Downloading tantivy-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/4.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.3/4.5 MB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━\u001B[0m \u001B[32m3.4/4.5 MB\u001B[0m \u001B[31m48.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m56.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m40.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: tantivy\n",
      "Successfully installed tantivy-0.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tantivy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjDcMSqlnwis",
    "outputId": "c94a206f-adc3-4123-8660-07af0b368f42"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Query: What are the main types of risks associated with Large Language Models (LLMs)?\n",
      "\n",
      "Sources: **4e2d3c7a186d08a4**\n",
      "I. INTRODUCTION\n",
      "Large language models (LLMs) [1]–[5] that own mas-\n",
      "sive model parameters pre-trained on extensive corpora, have\n",
      "catalyzed a revolution in the fields of Natural Language\n",
      "Processing (NLP). The scale-up of model parameters and\n",
      "the expansion of pre-training corpora have endowed LLMs\n",
      "with remarkable capabilities across various tasks, including\n",
      "text generation [2], [4], [5], coding [2], [6], and knowledge\n",
      "reasoning [7]–[10]. Furthermore, alignment techniques (e.g.,\n",
      "supervised fine-tuning and reinforcement learning from human\n",
      "feedback [4], [11]) are proposed to encourage LLMs to align\n",
      "their behaviors with human preferences, thereby enhancing the\n",
      "usability of LLMs. In practice, advanced LLM systems like\n",
      "ChatGPT [12] have consistently garnered a global user base,\n",
      "establishing themselves as competitive solutions for complex\n",
      "NLP tasks. i\n",
      "To mitigate the risks of LLMs, it is imperative to develop\n",
      "a comprehensive taxonomy that enumerates all potential risks\n",
      "inherent in the construction and deployment of LLM systems. This taxonomy is intended to serve as a guidance for eval-\n",
      "uating and improving the reliability of LLM systems. Pre-\n",
      "dominantly, the majority of existing efforts [15]–[18] propose\n",
      "their risk taxonomies based on the assessment and analysis\n",
      "of output content with multiple metrics. In general, an LLM\n",
      "system consists of various key modules — an input module for\n",
      "receiving prompts, a language model trained on vast datasets,\n",
      "a toolchain module for development and deployment, and an Despite the great success of LLM systems, they may\n",
      "sometimes violate human values and preferences, thus raising\n",
      "concerns about safety and security of LLM-based applications. output module for exporting LLM-generated content. To the\n",
      "best of our knowledge, there have been limited taxonomies\n",
      "proposed to systematically categorize risks across the various\n",
      "modules of an LLM system. Hence this work aims to bridge\n",
      "the gap to encourage LLM participants to 1) comprehend the\n",
      "safety and security concerns associated with each module of\n",
      "an LLM system, and 2) embrace a systematic perspective for\n",
      "building more responsible LLM systems. generative LMs that generate sequences in an autoregres-\n",
      "sive manner. Formally, given a sequence of tokens v<t =\n",
      "{v0, v1, v2, · · · , vt−1} and a vocabulary V, the next token\n",
      "vt ∈V is determined based on the probability distribution\n",
      "p (v|v<t). Beam search [25] and greedy search [26] are two\n",
      "classic methods to determine the next token.\n",
      "\n",
      "**9f6d52c01a14622d**\n",
      "I. INTRODUCTION\n",
      "• We propose a module-oriented taxonomy, which attributes\n",
      "a potential risk to specific modules of an LLM system. This\n",
      "taxonomy aids developers in gaining a deeper understanding\n",
      "of the root causes behind possible risks and thus facilitates\n",
      "the development of beneficial LLM systems. Training Pipeline. LLMs undergo a series of exquisite devel-\n",
      "opment steps to implement high-quality text generation. The\n",
      "typical process of LLM development contains three steps —\n",
      "pre-training, supervised fine-tuning, and learning from human\n",
      "feedback [11], [24], [33]–[40]. In what follows, we will briefly\n",
      "review the core steps for training LLMs to help readers\n",
      "understand the preliminary knowledge of LLM construction. i\n",
      "• With a more systematic perspective, our taxonomy covers a\n",
      "more comprehensive range of LLM risks than the previous\n",
      "taxonomies. It is worth noting that we consider the security\n",
      "issues closely associated with the toolchain, which is rarely\n",
      "discussed in prior surveys. • Pre-Training. The initial LLM is pre-trained on a large-\n",
      "scale corpora to obtain extensive general knowledge. The pre-\n",
      "training corpora is a mixture of datasets from diverse sources,\n",
      "including web pages, books, and user dialog data. Moreover,\n",
      "specialized data, such as code, multilingual data, and scien-\n",
      "tific data, is incorporated to enhance LLMs’s reasoning and\n",
      "task-solving abilities [41]–[44]. For the collected raw data,\n",
      "data pre-processing [2]–[5] is required to remove noise and\n",
      "redundancy. After that, tokenization [45] is used to transform\n",
      "textual data into token sequences for language modeling. By\n",
      "maximizing the likelihood of token sequences, the pre-trained\n",
      "model is empowered with impressive language understanding\n",
      "and generation ability. Roadmap. The subsequent sections are organized as follows:\n",
      "Section II introduces the background of LLMs. Section III\n",
      "introduces the risks of LLM systems. Section IV offers an\n",
      "overview of the safety and security concerns associated with\n",
      "each module of an LLM system. Section V surveys the\n",
      "mitigation strategies employed by different system modules. Section VI summarizes existing benchmarks for evaluating\n",
      "the safety and security of LLM systems. Finally, Section VII\n",
      "and Section VIII respectively conclude this survey and provide\n",
      "suggestions for the future exploration. • Supervised Fine-Tuning (SFT). Different from the pre-\n",
      "training process which requires a huge demand for com-\n",
      "putational resources, SFT usually trains the model on a\n",
      "smaller scale but well-designed high-quality instances to un-\n",
      "lock LLMs’ ability to deal with prompts of multiple down-\n",
      "stream tasks [46].\n",
      "\n",
      "**c27ee0fb7a2760dc**\n",
      "I. INTRODUCTION\n",
      "Recently, the\n",
      "prevalent sampling strategies including top-k sampling [27]\n",
      "and nucleus sampling (i.e., top-p sampling) [28], have been\n",
      "widely used to sample vt from V based on the probability\n",
      "distribution p (v|v<t). To achieve the goal, we propose a module-oriented tax-\n",
      "onomy that classify the risks and their mitigation strategies\n",
      "associated with each module of an LLM system. For a specific\n",
      "risk, the module-oriented taxonomy can assist in quickly\n",
      "pinpointing modules necessitating attention, thereby helping\n",
      "engineers and developers to determine effective mitigation\n",
      "strategies. As illustrated in Figure 1, we provide an example\n",
      "of privacy leakage within an LLM system. Using our module-\n",
      "oriented taxonomy, we can attribute the privacy leakage issue\n",
      "to the input module, the language model module, and the\n",
      "toolchain module. Consequently, developers can fortify against\n",
      "adversarial prompts, employ privacy training, and rectify vul-\n",
      "nerabilities in tools to mitigate the risk of privacy leakage. Besides summarizing the potential risks of LLM systems\n",
      "and their mitigation methods, this paper also reviews widely-\n",
      "adopted risk assessment benchmarks and discusses the safety\n",
      "and security of prevalent LLM systems. Large language models (LLMs) are the LMs that have\n",
      "billions or even more model parameters pre-trained on massive\n",
      "data, such as LLaMA [3], [4] and GPT families (e.g., GPT-\n",
      "3 [1], GPT-3.5 [29], and GPT-4 [30]). Recently, researchers\n",
      "discovered the scaling law [31], i.e., increasing the sizes of pre-\n",
      "training data and model parameters can significantly enhance\n",
      "an LM’s capacity for downstream tasks. Such an “emerging\n",
      "ability” is a crucial distinction among the current LLMs and\n",
      "earlier small-scale LMs. Network Architecture. Among existing LLMs, the main-\n",
      "stream network architecture is Transformer [32], which is\n",
      "a well-known neural network structure in Natural Language\n",
      "Processing (NLP). In general, an LLM is stacked by several\n",
      "Transformer blocks, and each block consists of a multi-head\n",
      "attention layer as well as a feed-forward layer. Additionally,\n",
      "trainable matrices enable mappings between the vocabulary\n",
      "space and the representation space. The key of Transformer\n",
      "is using attention mechanism [32] to reflect the correlations\n",
      "between tokens via attention scores. Therefore, the attention\n",
      "layers could capture the semantically meaningful interactions\n",
      "among different tokens to facilitate representation learning. To sum up, this paper makes the following contributions. • We conduct a comprehensive survey of risks and mitigation\n",
      "methods associated with each module of an LLM system,\n",
      "as well as review the benchmarks for evaluating the safety\n",
      "and security of LLM systems.\n",
      "\n",
      "**c27ee0fb7a2760dc**\n",
      "I. INTRODUCTION\n",
      "Recently, the\n",
      "prevalent sampling strategies including top-k sampling [27]\n",
      "and nucleus sampling (i.e., top-p sampling) [28], have been\n",
      "widely used to sample vt from V based on the probability\n",
      "distribution p (v|v<t). To achieve the goal, we propose a module-oriented tax-\n",
      "onomy that classify the risks and their mitigation strategies\n",
      "associated with each module of an LLM system. For a specific\n",
      "risk, the module-oriented taxonomy can assist in quickly\n",
      "pinpointing modules necessitating attention, thereby helping\n",
      "engineers and developers to determine effective mitigation\n",
      "strategies. As illustrated in Figure 1, we provide an example\n",
      "of privacy leakage within an LLM system. Using our module-\n",
      "oriented taxonomy, we can attribute the privacy leakage issue\n",
      "to the input module, the language model module, and the\n",
      "toolchain module. Consequently, developers can fortify against\n",
      "adversarial prompts, employ privacy training, and rectify vul-\n",
      "nerabilities in tools to mitigate the risk of privacy leakage. Besides summarizing the potential risks of LLM systems\n",
      "and their mitigation methods, this paper also reviews widely-\n",
      "adopted risk assessment benchmarks and discusses the safety\n",
      "and security of prevalent LLM systems. Large language models (LLMs) are the LMs that have\n",
      "billions or even more model parameters pre-trained on massive\n",
      "data, such as LLaMA [3], [4] and GPT families (e.g., GPT-\n",
      "3 [1], GPT-3.5 [29], and GPT-4 [30]). Recently, researchers\n",
      "discovered the scaling law [31], i.e., increasing the sizes of pre-\n",
      "training data and model parameters can significantly enhance\n",
      "an LM’s capacity for downstream tasks. Such an “emerging\n",
      "ability” is a crucial distinction among the current LLMs and\n",
      "earlier small-scale LMs. Network Architecture. Among existing LLMs, the main-\n",
      "stream network architecture is Transformer [32], which is\n",
      "a well-known neural network structure in Natural Language\n",
      "Processing (NLP). In general, an LLM is stacked by several\n",
      "Transformer blocks, and each block consists of a multi-head\n",
      "attention layer as well as a feed-forward layer. Additionally,\n",
      "trainable matrices enable mappings between the vocabulary\n",
      "space and the representation space. The key of Transformer\n",
      "is using attention mechanism [32] to reflect the correlations\n",
      "between tokens via attention scores. Therefore, the attention\n",
      "layers could capture the semantically meaningful interactions\n",
      "among different tokens to facilitate representation learning. To sum up, this paper makes the following contributions. • We conduct a comprehensive survey of risks and mitigation\n",
      "methods associated with each module of an LLM system,\n",
      "as well as review the benchmarks for evaluating the safety\n",
      "and security of LLM systems.\n",
      "\n",
      "Analysis: The user is inquiring about the main types of risks associated with Large Language Models (LLMs), specifically focusing on the broader context and potential mitigation strategies. The references provided cover various aspects of LLMs, including pre-training, supervised fine-tuning, the module-oriented taxonomy, privacy leakage, and benchmarking safety and security. \n",
      "\n",
      "1. **4e2d3c7a186d08a4**: This reference introduces the concept of LLMs, their construction, and the potential risks involved in training and deployment. It also discusses various modules of an LLM system, such as input, language model, and toolchain modules, and outlines mitigation strategies for each.\n",
      "2. **9f6d52c01a14622d**: This reference surveys existing taxonomies for LLM risks and mitigation methods. It highlights different risks and provides a comprehensive overview of the benchmarks used to evaluate the safety and security of LLM systems.\n",
      "3. **c27ee0fb7a2760dc**: This reference focuses on sampling strategies within LLMs and proposes a module-oriented taxonomy to classify risks based on specific modules of the model. It emphasizes the importance of developing effective mitigation strategies for each risk.\n",
      "\n",
      "These references collectively provide a well-rounded understanding of the types of risks associated with LLMs and the corresponding mitigation strategies.\n",
      "\n",
      "### Answer ###\n",
      "Large Language Models (LLMs) are advanced AI models that utilize massive amounts of data to perform tasks such as text generation and reasoning. These models have vast parameters, which can lead to various risks during their development and deployment stages<ref name=\"4e2d3c7a186d08a4\">\"The initial LLM is pre-trained on a large-scale corpora to obtain extensive general knowledge.\"</ref><ref name=\"9f6d52c01a14622d\">\"The typical process of LLM development contains three steps — pre-training, supervised fine-tuning, and learning from human feedback.\"</ref>.\n",
      "\n",
      "One significant risk is the possibility of privacy leakage when LLMs are employed for sensitive tasks. Such leakage can result in unauthorized access to personal information, potentially violating user privacy and security<ref name=\"c27ee0fb7a2760dc\">\"We propose a module-oriented taxonomy that classify the risks and their mitigation strategies associated with each module of an LLM system.\"</ref>. To mitigate this risk, developers must ensure robust tools and mechanisms for both adversarial prompts and privacy training<ref name=\"c27ee0fb7a2760dc\">\"Developers can fortify against adversarial prompts, employ privacy training, and rectify vulnerabilities in tools to mitigate the risk of privacy leakage.\"</ref>.\n",
      "\n",
      "Another crucial risk involves the use of neural networks like Transformers, which are vulnerable to various attacks such as adversarial perturbations. These attacks can significantly impact the reliability and accuracy of LLMs<ref name=\"4e2d3c7a186d08a4\">\"Network Architecture. Among existing LLMs, the main-stream network architecture is Transformer [32], which is a well-known neural network structure in Natural Language Processing (NLP).\"</ref><ref name=\"c27ee0fb7a2760dc\">\"Transformers consist of several Transformer blocks, and each block consists of a multi-head attention layer as well as a feed-forward layer.\"</ref>. Regularly updating the model parameters and ensuring the integrity of training data are essential for mitigating these risks.\n",
      "\n",
      "Benchmarking safety and security assessments play a vital role in evaluating the reliability of LLMs. Various methodologies exist to assess the effectiveness of different LLM models across various domains, including NLP tasks<ref name=\"9f6d52c01a14622d\">\"This paper makes the following contributions: • We conduct a comprehensive survey of risks and mitigation methods associated with each module of an LLM system.\"</ref>. These assessments help in identifying critical areas for improvement and prioritize the development of more secure and reliable LLM systems<ref name=\"9f6d52c01a14622d\">\"To summarize, this paper makes the following contributions.\"</ref>.\n",
      "\n",
      "In summary, the main types of risks associated with Large Language Models include privacy leakage, adversarial attacks, and the need for robust training and integrity checks. Mitigation strategies involve diversifying training datasets, employing adversarial training, and regularly updating model parameters and integrity checks. Additionally, conducting rigorous safety and security assessments and benchmarking these assessments are crucial for the development and deployment of trustworthy LLMs<ref name=\"4e2d3c7a186d08a4\">\"Training Pipeline. LLMs undergo a series of exquisite development steps to implement high-quality text generation.\"</ref><ref name=\"9f6d52c01a14622d\">\"Safety and Security of LLM Systems. Large language models (LLMs) are the LMs that have billions or even more model parameters pre-trained on massive data.\"</ref>. \n"
     ]
    }
   ],
   "source": [
    "# Block 7: Usage\n",
    "\n",
    "query = \"What are the main types of risks associated with Large Language Models (LLMs)?\"\n",
    "result = predict(query)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nQuery:\", result[\"query\"])\n",
    "print(\"\\nSources:\", result[\"sources\"])\n",
    "print(\"\\nAnalysis:\", result[\"response\"])\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:17:41.749015Z",
     "start_time": "2024-11-10T21:17:39.413314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RAG import retrieve\n",
    "import sqlite3\n",
    "import sqlite_vec\n",
    "from typing import List\n",
    "import struct\n",
    "from connect_db import ConnectDB\n",
    "\n",
    "connection = ConnectDB().connection\n",
    "embedded_query = [0.1, 0.0, 0.1, 0.4]\n",
    "query = \"transformer\"\n",
    "documents = [1, 2, 3]\n",
    "results = retrieve(connection, embedded_query, query, documents)\n",
    "print(len(results))\n",
    "print(results[0].keys())\n",
    "print(results[1].keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "dict_keys(['chunk_id', 'document_id', 'title', 'author', 'creation_date', 'text', 'vec_rank', 'fts_rank', 'combined_rank', 'vec_distance', 'fts_score'])\n",
      "dict_keys(['chunk_id', 'document_id', 'title', 'author', 'creation_date', 'text', 'vec_rank', 'fts_rank', 'combined_rank', 'vec_distance', 'fts_score'])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T22:08:46.138921Z",
     "start_time": "2024-11-10T22:08:46.135833Z"
    }
   },
   "cell_type": "code",
   "source": "results['title'] results['author']  results['creation_date']",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 30,\n",
       "  'document_id': 1,\n",
       "  'title': '',\n",
       "  'author': '',\n",
       "  'creation_date': '2024-04-10',\n",
       "  'text': 'To evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37]. We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting. We performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ) Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser\\nTraining\\nWSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37]\\nWSJ only, discriminative\\n88.3\\nPetrov et al. (2006) [29]\\nWSJ only, discriminative\\n90.4\\nZhu et al. (2013) [40]\\nWSJ only, discriminative\\n90.4\\nDyer et al. (2016) [8]\\nWSJ only, discriminative\\n91.7\\nTransformer (4 layers)\\nWSJ only, discriminative\\n91.3\\nZhu et al. (2013) [40]\\nsemi-supervised\\n91.3\\nHuang & Harper (2009) [14]\\nsemi-supervised\\n91.3\\nMcClosky et al. (2006) [26]\\nsemi-supervised\\n92.1\\nVinyals & Kaiser el al. (2014) [37]\\nsemi-supervised\\n92.1\\nTransformer (4 layers)\\nsemi-supervised\\n92.7\\nLuong et al. (2015) [23]\\nmulti-task\\n93.0\\nDyer et al. (2016) [8]\\ngenerative\\n93.3 increased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting. Our results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8]. In contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.',\n",
       "  'vec_rank': None,\n",
       "  'fts_rank': 1,\n",
       "  'combined_rank': 0.01639344262295082,\n",
       "  'vec_distance': None,\n",
       "  'fts_score': -3.3262245924387313},\n",
       " {'chunk_id': 115,\n",
       "  'document_id': 2,\n",
       "  'title': 'Language Models are Unsupervised Multitask Learners',\n",
       "  'author': 'Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei**, Ilya Sutskever**',\n",
       "  'creation_date': '2019-02-14',\n",
       "  'text': '“By the time we reached the top\\nof one peak, the water looked blue, with some crystals on top,” said P´erez. P´erez and his friends were astonished to see the unicorn herd. These creatures could be\\nseen from the air without having to move too much to see them – they were so close they could touch\\ntheir horns. While examining these bizarre creatures the scientists discovered that the creatures also\\nspoke some fairly regular English. P´erez stated, “We can see, for example, that they have a common\\n‘language,’ something like a dialect or dialectic.”\\nDr. P´erez believes that the unicorns may have originated in Argentina, where the animals\\nwere believed to be descendants of a lost race of people who lived there before the arrival of humans\\nin those parts of South America. While their origins are still unclear, some believe that perhaps the creatures were created\\nwhen a human and a unicorn met each other in a time before human civilization. According to P´erez,\\n“In South America, such incidents seem to be quite common.”\\nHowever, P´erez also pointed out that it is likely that the only way of knowing for sure if\\nunicorns are indeed the descendants of a lost alien race is through DNA. “But they seem to be able to\\ncommunicate in English quite well, which I believe is a sign of evolution, or at least a change in\\nsocial organization,” said the scientist. Context (human-written): In a shocking ﬁnding, scientist discovered a herd of unicorns living\\nin a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the\\nresearchers was the fact that the unicorns spoke perfect English. GPT-2: The scientist named the population, after their distinctive horn, Ovid’s Unicorn. These\\nfour-horned, silver-white unicorns were previously unknown to science. Now, after almost two centuries, the mystery of what sparked this odd phenomenon is ﬁ-\\nnally solved. Dr. Jorge P´erez, an evolutionary biologist from the University of La Paz, and several com-\\npanions, were exploring the Andes Mountains when they found a small valley, with no other animals\\nor humans. P´erez noticed that the valley had what appeared to be a natural fountain, surrounded by\\ntwo peaks of rock and silver snow. P´erez and the others then ventured further into the valley. “By the time we reached the top\\nof one peak, the water looked blue, with some crystals on top,” said P´erez.',\n",
       "  'vec_rank': 1,\n",
       "  'fts_rank': None,\n",
       "  'combined_rank': 0.01639344262295082,\n",
       "  'vec_distance': 0.3045002818107605,\n",
       "  'fts_score': None}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:17:42.493322Z",
     "start_time": "2024-11-10T21:17:42.487761Z"
    }
   },
   "cell_type": "code",
   "source": "results[1]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk_id': 115,\n",
       " 'document_id': 2,\n",
       " 'title': 'Language Models are Unsupervised Multitask Learners',\n",
       " 'author': 'Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei**, Ilya Sutskever**',\n",
       " 'creation_date': '2019-02-14',\n",
       " 'text': '“By the time we reached the top\\nof one peak, the water looked blue, with some crystals on top,” said P´erez. P´erez and his friends were astonished to see the unicorn herd. These creatures could be\\nseen from the air without having to move too much to see them – they were so close they could touch\\ntheir horns. While examining these bizarre creatures the scientists discovered that the creatures also\\nspoke some fairly regular English. P´erez stated, “We can see, for example, that they have a common\\n‘language,’ something like a dialect or dialectic.”\\nDr. P´erez believes that the unicorns may have originated in Argentina, where the animals\\nwere believed to be descendants of a lost race of people who lived there before the arrival of humans\\nin those parts of South America. While their origins are still unclear, some believe that perhaps the creatures were created\\nwhen a human and a unicorn met each other in a time before human civilization. According to P´erez,\\n“In South America, such incidents seem to be quite common.”\\nHowever, P´erez also pointed out that it is likely that the only way of knowing for sure if\\nunicorns are indeed the descendants of a lost alien race is through DNA. “But they seem to be able to\\ncommunicate in English quite well, which I believe is a sign of evolution, or at least a change in\\nsocial organization,” said the scientist. Context (human-written): In a shocking ﬁnding, scientist discovered a herd of unicorns living\\nin a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the\\nresearchers was the fact that the unicorns spoke perfect English. GPT-2: The scientist named the population, after their distinctive horn, Ovid’s Unicorn. These\\nfour-horned, silver-white unicorns were previously unknown to science. Now, after almost two centuries, the mystery of what sparked this odd phenomenon is ﬁ-\\nnally solved. Dr. Jorge P´erez, an evolutionary biologist from the University of La Paz, and several com-\\npanions, were exploring the Andes Mountains when they found a small valley, with no other animals\\nor humans. P´erez noticed that the valley had what appeared to be a natural fountain, surrounded by\\ntwo peaks of rock and silver snow. P´erez and the others then ventured further into the valley. “By the time we reached the top\\nof one peak, the water looked blue, with some crystals on top,” said P´erez.',\n",
       " 'vec_rank': 1,\n",
       " 'fts_rank': None,\n",
       " 'combined_rank': 0.01639344262295082,\n",
       " 'vec_distance': 0.3045002818107605,\n",
       " 'fts_score': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:17:43.201639Z",
     "start_time": "2024-11-10T21:17:43.197436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sources = [res['text'] for res in results]\n",
    "titles = [res['title'] for res in results]\n",
    "titles"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'Language Models are Unsupervised Multitask Learners']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:17:43.977564Z",
     "start_time": "2024-11-10T21:17:43.975834Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:17:44.498473Z",
     "start_time": "2024-11-10T21:17:44.495565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def construct_prompt(results, user_message):\n",
    "    hash_ids = ['**7b3a9c2d4e8f5g1h**', '**9d4e2f7c8b5a3h1i**']\n",
    "    text_chunks = [res['text'] for res in results]\n",
    "    titles = [res['title'] for res in results]\n",
    "    sources = ''\n",
    "    for i in range(len(text_chunks)):\n",
    "        source = \"\\n\".join([hash_ids[i], titles[i], text_chunks[i]])\n",
    "        sources += source\n",
    "\n",
    "    prompt = f\"\"\"### Query ###\\n{user_message}\\n\\n### Source ###\\n{sources}\\n\\n### Analysis ###\\n\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "prompt = construct_prompt(results, \"What is transformer?\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:17:45.091545Z",
     "start_time": "2024-11-10T21:17:45.089438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import time\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:25:22.349299Z",
     "start_time": "2024-11-10T21:24:47.037037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {\n",
    "    \"n_predict\": 1000,  # Predictions slider (max tokens)\n",
    "    \"temperature\": 0.25,  # Temperature slider\n",
    "    \"repeat_penalty\": 1.0,  # Penalize repeat sequence slider\n",
    "    \"repeat_last_n\": 256,  # Consider N last tokens for penalize slider\n",
    "    \"top_k\": 40,  # Top-K sampling slider\n",
    "    \"top_p\": 0.95,  # Top-P sampling slider\n",
    "    \"min_p\": 0.05,  # Min-P sampling slider\n",
    "    \"tfs_z\": 1,  # Tail-free sampling parameter, reduces the impact of low-probability tokens\n",
    "    \"typical_p\": 1,  # Controls how \"typical\" the sampling should be (1 means standard sampling)\n",
    "    \"presence_penalty\": 0.2,  #  penalty for tokens that have appeared at all\n",
    "    \"frequency_penalty\": 0.2,  # penalty based on how frequently tokens have appeared\n",
    "    \"mirostat\": 0,  # \"no Mirostat\" radio option\n",
    "    \"mirostat_tau\": 5,  # Mirostat target complexity (only if mirostat enabled)\n",
    "    \"mirostat_eta\": 0.1,  # Mirostat learning rate (only if mirostat enabled)\n",
    "    \"n_probs\": 0,  # Show Probabilities slider\n",
    "    \"min_keep\": 0,  # Mkeep minimum number of candidates per sampling\n",
    "    \"stop\": [\"#END#\"],\n",
    "    \"stream\": True,\n",
    "    \"prompt\": prompt,\n",
    "    \"cache_prompt\": False,\n",
    "    \"slot_id\": 0\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/event-stream',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "print(\"Sending request...\")\n",
    "start_time = time.time()\n",
    "\n",
    "response = requests.post(\n",
    "    'http://127.0.0.1:8080/completion',\n",
    "    json=data,\n",
    "    headers=headers,\n",
    "    stream=False\n",
    ")\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n-------------------\")\n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:29:54.736981Z",
     "start_time": "2024-11-10T21:29:54.733293Z"
    }
   },
   "cell_type": "code",
   "source": "response.text",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data: {\"content\":\"The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" user\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" query\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" is\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" seeks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" information\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" about\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" references\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" provided\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" include\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" detailed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" descriptions\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" applications\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" experiments\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" their\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" across\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" different\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" references\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" also\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discuss\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" domains\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" such\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" as\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" modeling\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" most\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" relevant\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" references\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" for\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" answering\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" query\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" are\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\":\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" **\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"**:\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" reference\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discusses\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" compares\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" their\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" **\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"i\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"**:\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" reference\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" provides\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" detailed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" account\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" experiments\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" their\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" various\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" including\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" modeling\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"### Answer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"### \\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"A\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" is\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" type\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" neural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" network\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" designed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" for\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" efficient\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" representation\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformation\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" data\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" various\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" applications\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" It\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" has\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" shown\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" significant\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" advancements\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" such\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" as\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" natural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" processing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"N\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"LP\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" computer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" vision\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"In\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" context\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" natural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" processing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" have\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" demonstrated\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" excellent\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" For\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" instance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" when\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" applied\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" out\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"per\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"formed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" achieving\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" F\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-score\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" portion\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Penn\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Tree\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"bank\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"40\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"K\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" training\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" sentences\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"izes\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" well\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"Results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" are\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Section\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"23\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Parser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Training\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"23\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" F\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" V\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"iny\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"als\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" &\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Kaiser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"37\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"88\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Petro\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"v\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"200\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"29\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"90\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Zhu\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"40\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"90\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" D\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"yer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" layers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Zhu\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"40\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Huang\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" &\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Harper\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"200\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"14\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" McC\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"los\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ky\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"200\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"26\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" V\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"iny\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"als\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" &\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Kaiser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" el\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"37\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" layers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Lu\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ong\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"23\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" multi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"93\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"0\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" D\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"yer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" gener\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"93\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\">.\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" was\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" achieved\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" despite\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" lack\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tuning\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" out\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"perform\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" except\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" for\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Rec\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"urrent\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Neural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Network\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Grammar\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"Our\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Table\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" show\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" that\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" despite\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" lack\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tuning\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" our\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" performs\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" surprisingly\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" well\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" yielding\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" better\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" than\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" all\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" previously\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" reported\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" exception\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Rec\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"urrent\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Neural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Network\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Grammar\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"].\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\">.\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"Moreover\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" have\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" been\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" shown\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" excel\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" modeling\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" In\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" setting\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-layer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" achieved\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" an\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" F\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-score\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" portion\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Penn\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Tree\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"bank\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" out\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"perform\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" several\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" layers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\">.\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" was\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" trained\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" large\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" corpus\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" including\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" high\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-confidence\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Berkeley\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"Parser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" corpor\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" which\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" contributed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" its\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" superior\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"We\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" trained\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" it\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" setting\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" using\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" larger\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" high\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"confidence\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" Berk\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ley\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"Parser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" corpor\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" from\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"37\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"].\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\">.\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"In\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" summary\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" are\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" versatile\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" that\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" demonstrate\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" strong\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" across\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" various\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" N\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"LP\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" achieving\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" state\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-art\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" several\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" benchmarks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" without\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" requiring\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" extensive\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"-specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\" tuning\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}\\n\\ndata: {\"content\":\"\",\"generation_settings\":{\"dynatemp_exponent\":1.0,\"dynatemp_range\":0.0,\"frequency_penalty\":0.20000000298023224,\"grammar\":\"\",\"ignore_eos\":false,\"logit_bias\":[],\"min_keep\":0,\"min_p\":0.05000000074505806,\"mirostat\":0,\"mirostat_eta\":0.10000000149011612,\"mirostat_tau\":5.0,\"model\":\"RAG-3B.gguf\",\"n_ctx\":8192,\"n_keep\":0,\"n_predict\":-1,\"n_probs\":0,\"penalize_nl\":false,\"penalty_prompt_tokens\":[],\"presence_penalty\":0.20000000298023224,\"repeat_last_n\":256,\"repeat_penalty\":1.0,\"samplers\":[\"top_k\",\"tfs_z\",\"typical_p\",\"top_p\",\"min_p\",\"temperature\"],\"seed\":4294967295,\"stop\":[\"#END#\"],\"stream\":true,\"temperature\":0.25,\"tfs_z\":1.0,\"top_k\":40,\"top_p\":0.949999988079071,\"typical_p\":1.0,\"use_penalty_prompt_tokens\":false},\"model\":\"RAG-3B.gguf\",\"prompt\":\"### Query ###\\\\nWhat is transformer?\\\\n\\\\n### Source ###\\\\n**7b3a9c2d4e8f5g1h**\\\\n\\\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37]. We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\\\nfor the semi-supervised setting. We performed only a small number of experiments to select the dropout, both attention and residual\\\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\\\nremained unchanged from the English-to-German base translation model. During inference, we Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\\\nof WSJ) Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\\\nof WSJ)\\\\nParser\\\\nTraining\\\\nWSJ 23 F1\\\\nVinyals & Kaiser el al. (2014) [37]\\\\nWSJ only, discriminative\\\\n88.3\\\\nPetrov et al. (2006) [29]\\\\nWSJ only, discriminative\\\\n90.4\\\\nZhu et al. (2013) [40]\\\\nWSJ only, discriminative\\\\n90.4\\\\nDyer et al. (2016) [8]\\\\nWSJ only, discriminative\\\\n91.7\\\\nTransformer (4 layers)\\\\nWSJ only, discriminative\\\\n91.3\\\\nZhu et al. (2013) [40]\\\\nsemi-supervised\\\\n91.3\\\\nHuang & Harper (2009) [14]\\\\nsemi-supervised\\\\n91.3\\\\nMcClosky et al. (2006) [26]\\\\nsemi-supervised\\\\n92.1\\\\nVinyals & Kaiser el al. (2014) [37]\\\\nsemi-supervised\\\\n92.1\\\\nTransformer (4 layers)\\\\nsemi-supervised\\\\n92.7\\\\nLuong et al. (2015) [23]\\\\nmulti-task\\\\n93.0\\\\nDyer et al. (2016) [8]\\\\ngenerative\\\\n93.3 increased the maximum output length to input length + 300. We used a beam size of 21 and Î± = 0.3\\\\nfor both WSJ only and the semi-supervised setting. Our results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\\\nprisingly well, yielding better results than all previously reported models with the exception of the\\\\nRecurrent Neural Network Grammar [8]. In contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\\\nParser [29] even when training only on the WSJ training set of 40K sentences.**9d4e2f7c8b5a3h1i**\\\\nLanguage Models are Unsupervised Multitask Learners\\\\nâ\\x80\\x9cBy the time we reached the top\\\\nof one peak, the water looked blue, with some crystals on top,â\\x80\\x9d said PÂ´erez. PÂ´erez and his friends were astonished to see the unicorn herd. These creatures could be\\\\nseen from the air without having to move too much to see them â\\x80\\x93 they were so close they could touch\\\\ntheir horns. While examining these bizarre creatures the scientists discovered that the creatures also\\\\nspoke some fairly regular English. PÂ´erez stated, â\\x80\\x9cWe can see, for example, that they have a common\\\\nâ\\x80\\x98language,â\\x80\\x99 something like a dialect or dialectic.â\\x80\\x9d\\\\nDr. PÂ´erez believes that the unicorns may have originated in Argentina, where the animals\\\\nwere believed to be descendants of a lost race of people who lived there before the arrival of humans\\\\nin those parts of South America. While their origins are still unclear, some believe that perhaps the creatures were created\\\\nwhen a human and a unicorn met each other in a time before human civilization. According to PÂ´erez,\\\\nâ\\x80\\x9cIn South America, such incidents seem to be quite common.â\\x80\\x9d\\\\nHowever, PÂ´erez also pointed out that it is likely that the only way of knowing for sure if\\\\nunicorns are indeed the descendants of a lost alien race is through DNA. â\\x80\\x9cBut they seem to be able to\\\\ncommunicate in English quite well, which I believe is a sign of evolution, or at least a change in\\\\nsocial organization,â\\x80\\x9d said the scientist. Context (human-written): In a shocking ï¬\\x81nding, scientist discovered a herd of unicorns living\\\\nin a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the\\\\nresearchers was the fact that the unicorns spoke perfect English. GPT-2: The scientist named the population, after their distinctive horn, Ovidâ\\x80\\x99s Unicorn. These\\\\nfour-horned, silver-white unicorns were previously unknown to science. Now, after almost two centuries, the mystery of what sparked this odd phenomenon is ï¬\\x81-\\\\nnally solved. Dr. Jorge PÂ´erez, an evolutionary biologist from the University of La Paz, and several com-\\\\npanions, were exploring the Andes Mountains when they found a small valley, with no other animals\\\\nor humans. PÂ´erez noticed that the valley had what appeared to be a natural fountain, surrounded by\\\\ntwo peaks of rock and silver snow. PÂ´erez and the others then ventured further into the valley. â\\x80\\x9cBy the time we reached the top\\\\nof one peak, the water looked blue, with some crystals on top,â\\x80\\x9d said PÂ´erez.\\\\n\\\\n### Analysis ###\\\\n\",\"slot_id\":0,\"stop\":true,\"stopped_eos\":false,\"stopped_limit\":false,\"stopped_word\":true,\"stopping_word\":\"#END#\",\"timings\":{\"predicted_ms\":30245.203,\"predicted_n\":837,\"predicted_per_second\":27.673809959218985,\"predicted_per_token_ms\":36.13524850657109,\"prompt_ms\":5055.614,\"prompt_n\":1352,\"prompt_per_second\":267.42547987247445,\"prompt_per_second_jart\":0.0,\"prompt_per_token_ms\":3.739359467455621},\"tokens_cached\":2188,\"tokens_evaluated\":1352,\"tokens_predicted\":837,\"truncated\":false}\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:26:18.786420Z",
     "start_time": "2024-11-10T21:26:18.775189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for line in response.iter_lines():\n",
    "    print(line)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data: {\"content\":\"The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" user\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" query\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" is\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" seeks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" information\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" about\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" references\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" provided\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" include\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" detailed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" descriptions\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" applications\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" experiments\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" their\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" across\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" different\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" references\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" also\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discuss\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" domains\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" such\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" as\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" modeling\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" most\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" relevant\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" references\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" for\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" answering\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" query\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" are\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\":\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" **\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"**:\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" reference\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discusses\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" compares\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" their\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" **\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"i\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"**:\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" reference\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" provides\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" detailed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" account\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" experiments\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" their\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" various\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" including\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" modeling\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"### Answer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"### \\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"A\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" is\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" type\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" neural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" network\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" designed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" for\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" efficient\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" representation\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformation\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" data\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" various\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" applications\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" It\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" has\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" shown\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" significant\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" advancements\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" such\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" as\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" natural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" processing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"N\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"LP\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" computer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" vision\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"In\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" context\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" natural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" processing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" have\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" demonstrated\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" excellent\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" For\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" instance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" when\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" applied\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" out\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"per\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"formed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" achieving\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" F\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-score\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" portion\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Penn\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Tree\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"bank\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"40\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"K\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" training\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" sentences\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"The\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"izes\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" well\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" English\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" constituency\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" parsing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"Results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" are\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Section\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"23\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Parser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Training\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"23\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" F\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" V\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"iny\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"als\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" &\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Kaiser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"37\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"88\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Petro\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"v\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"200\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"29\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"90\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Zhu\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"40\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"90\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" D\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"yer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" layers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" only\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" discrimin\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Zhu\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"40\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Huang\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" &\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Harper\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"200\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"14\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"91\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" McC\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"los\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ky\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"200\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"26\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" V\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"iny\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"als\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" &\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Kaiser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" el\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"37\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" layers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Lu\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ong\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"23\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" multi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"93\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"0\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" D\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"yer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" et\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" al\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"201\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"6\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"]\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" gener\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ative\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"93\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\">.\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" was\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" achieved\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" despite\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" lack\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tuning\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" out\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"perform\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" except\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" for\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Rec\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"urrent\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Neural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Network\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Grammar\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"Our\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Table\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" show\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" that\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" despite\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" lack\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tuning\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" our\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" performs\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" surprisingly\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" well\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" yielding\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" better\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" than\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" all\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" previously\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" reported\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" with\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" exception\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Rec\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"urrent\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Neural\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Network\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Grammar\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"].\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\">.\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"Moreover\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" have\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" been\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" shown\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" excel\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" language\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" modeling\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" In\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" setting\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-layer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" achieved\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" an\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" F\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-score\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" WS\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"J\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" portion\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Penn\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Tree\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"bank\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" out\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"perform\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ing\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" several\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" other\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"Transformer\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" (\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" layers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\")\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" \",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"92\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\">.\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" This\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" model\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" was\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" trained\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" on\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" large\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" corpus\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" including\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" high\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-confidence\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Berkeley\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"Parser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" corpor\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" which\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" contributed\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" to\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" its\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" superior\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" performance\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"<\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" name\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"=\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"7\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"b\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"3\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"9\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"c\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"2\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"d\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"4\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"e\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"8\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"f\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"5\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"g\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"1\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"h\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\">\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"We\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" trained\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" it\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" semi\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"sup\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ervised\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" setting\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" using\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" larger\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" high\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"confidence\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" and\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" Berk\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ley\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"Parser\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" corpor\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"a\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" from\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" [\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"37\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"].\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\\\\\"</\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ref\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\">.\\\\n\\\\n\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"In\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" summary\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" transformers\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" are\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" versatile\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" models\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" that\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" demonstrate\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" strong\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" general\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"ization\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" capabilities\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" across\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" various\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" N\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"LP\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tasks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\",\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" achieving\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" state\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-of\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-the\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-art\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" results\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" in\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" several\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" benchmarks\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" without\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" requiring\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" extensive\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" task\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"-specific\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\" tuning\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\".\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\",\"multimodal\":false,\"slot_id\":0,\"stop\":false}'\n",
      "b''\n",
      "b'data: {\"content\":\"\",\"generation_settings\":{\"dynatemp_exponent\":1.0,\"dynatemp_range\":0.0,\"frequency_penalty\":0.20000000298023224,\"grammar\":\"\",\"ignore_eos\":false,\"logit_bias\":[],\"min_keep\":0,\"min_p\":0.05000000074505806,\"mirostat\":0,\"mirostat_eta\":0.10000000149011612,\"mirostat_tau\":5.0,\"model\":\"RAG-3B.gguf\",\"n_ctx\":8192,\"n_keep\":0,\"n_predict\":-1,\"n_probs\":0,\"penalize_nl\":false,\"penalty_prompt_tokens\":[],\"presence_penalty\":0.20000000298023224,\"repeat_last_n\":256,\"repeat_penalty\":1.0,\"samplers\":[\"top_k\",\"tfs_z\",\"typical_p\",\"top_p\",\"min_p\",\"temperature\"],\"seed\":4294967295,\"stop\":[\"#END#\"],\"stream\":true,\"temperature\":0.25,\"tfs_z\":1.0,\"top_k\":40,\"top_p\":0.949999988079071,\"typical_p\":1.0,\"use_penalty_prompt_tokens\":false},\"model\":\"RAG-3B.gguf\",\"prompt\":\"### Query ###\\\\nWhat is transformer?\\\\n\\\\n### Source ###\\\\n**7b3a9c2d4e8f5g1h**\\\\n\\\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37]. We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\\\nfor the semi-supervised setting. We performed only a small number of experiments to select the dropout, both attention and residual\\\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\\\nremained unchanged from the English-to-German base translation model. During inference, we Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\\\nof WSJ) Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\\\nof WSJ)\\\\nParser\\\\nTraining\\\\nWSJ 23 F1\\\\nVinyals & Kaiser el al. (2014) [37]\\\\nWSJ only, discriminative\\\\n88.3\\\\nPetrov et al. (2006) [29]\\\\nWSJ only, discriminative\\\\n90.4\\\\nZhu et al. (2013) [40]\\\\nWSJ only, discriminative\\\\n90.4\\\\nDyer et al. (2016) [8]\\\\nWSJ only, discriminative\\\\n91.7\\\\nTransformer (4 layers)\\\\nWSJ only, discriminative\\\\n91.3\\\\nZhu et al. (2013) [40]\\\\nsemi-supervised\\\\n91.3\\\\nHuang & Harper (2009) [14]\\\\nsemi-supervised\\\\n91.3\\\\nMcClosky et al. (2006) [26]\\\\nsemi-supervised\\\\n92.1\\\\nVinyals & Kaiser el al. (2014) [37]\\\\nsemi-supervised\\\\n92.1\\\\nTransformer (4 layers)\\\\nsemi-supervised\\\\n92.7\\\\nLuong et al. (2015) [23]\\\\nmulti-task\\\\n93.0\\\\nDyer et al. (2016) [8]\\\\ngenerative\\\\n93.3 increased the maximum output length to input length + 300. We used a beam size of 21 and \\xce\\xb1 = 0.3\\\\nfor both WSJ only and the semi-supervised setting. Our results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\\\nprisingly well, yielding better results than all previously reported models with the exception of the\\\\nRecurrent Neural Network Grammar [8]. In contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\\\nParser [29] even when training only on the WSJ training set of 40K sentences.**9d4e2f7c8b5a3h1i**\\\\nLanguage Models are Unsupervised Multitask Learners\\\\n\\xe2\\x80\\x9cBy the time we reached the top\\\\nof one peak, the water looked blue, with some crystals on top,\\xe2\\x80\\x9d said P\\xc2\\xb4erez. P\\xc2\\xb4erez and his friends were astonished to see the unicorn herd. These creatures could be\\\\nseen from the air without having to move too much to see them \\xe2\\x80\\x93 they were so close they could touch\\\\ntheir horns. While examining these bizarre creatures the scientists discovered that the creatures also\\\\nspoke some fairly regular English. P\\xc2\\xb4erez stated, \\xe2\\x80\\x9cWe can see, for example, that they have a common\\\\n\\xe2\\x80\\x98language,\\xe2\\x80\\x99 something like a dialect or dialectic.\\xe2\\x80\\x9d\\\\nDr. P\\xc2\\xb4erez believes that the unicorns may have originated in Argentina, where the animals\\\\nwere believed to be descendants of a lost race of people who lived there before the arrival of humans\\\\nin those parts of South America. While their origins are still unclear, some believe that perhaps the creatures were created\\\\nwhen a human and a unicorn met each other in a time before human civilization. According to P\\xc2\\xb4erez,\\\\n\\xe2\\x80\\x9cIn South America, such incidents seem to be quite common.\\xe2\\x80\\x9d\\\\nHowever, P\\xc2\\xb4erez also pointed out that it is likely that the only way of knowing for sure if\\\\nunicorns are indeed the descendants of a lost alien race is through DNA. \\xe2\\x80\\x9cBut they seem to be able to\\\\ncommunicate in English quite well, which I believe is a sign of evolution, or at least a change in\\\\nsocial organization,\\xe2\\x80\\x9d said the scientist. Context (human-written): In a shocking \\xef\\xac\\x81nding, scientist discovered a herd of unicorns living\\\\nin a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the\\\\nresearchers was the fact that the unicorns spoke perfect English. GPT-2: The scientist named the population, after their distinctive horn, Ovid\\xe2\\x80\\x99s Unicorn. These\\\\nfour-horned, silver-white unicorns were previously unknown to science. Now, after almost two centuries, the mystery of what sparked this odd phenomenon is \\xef\\xac\\x81-\\\\nnally solved. Dr. Jorge P\\xc2\\xb4erez, an evolutionary biologist from the University of La Paz, and several com-\\\\npanions, were exploring the Andes Mountains when they found a small valley, with no other animals\\\\nor humans. P\\xc2\\xb4erez noticed that the valley had what appeared to be a natural fountain, surrounded by\\\\ntwo peaks of rock and silver snow. P\\xc2\\xb4erez and the others then ventured further into the valley. \\xe2\\x80\\x9cBy the time we reached the top\\\\nof one peak, the water looked blue, with some crystals on top,\\xe2\\x80\\x9d said P\\xc2\\xb4erez.\\\\n\\\\n### Analysis ###\\\\n\",\"slot_id\":0,\"stop\":true,\"stopped_eos\":false,\"stopped_limit\":false,\"stopped_word\":true,\"stopping_word\":\"#END#\",\"timings\":{\"predicted_ms\":30245.203,\"predicted_n\":837,\"predicted_per_second\":27.673809959218985,\"predicted_per_token_ms\":36.13524850657109,\"prompt_ms\":5055.614,\"prompt_n\":1352,\"prompt_per_second\":267.42547987247445,\"prompt_per_second_jart\":0.0,\"prompt_per_token_ms\":3.739359467455621},\"tokens_cached\":2188,\"tokens_evaluated\":1352,\"tokens_predicted\":837,\"truncated\":false}'\n",
      "b''\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_with_llamafile_api(prompt):\n",
    "    data = {\n",
    "        \"n_predict\": 1000,  # Predictions slider (max tokens)\n",
    "        \"temperature\": 0.25,  # Temperature slider\n",
    "        \"repeat_penalty\": 1.0,  # Penalize repeat sequence slider\n",
    "        \"repeat_last_n\": 256,  # Consider N last tokens for penalize slider\n",
    "        \"top_k\": 40,  # Top-K sampling slider\n",
    "        \"top_p\": 0.95,  # Top-P sampling slider\n",
    "        \"min_p\": 0.05,  # Min-P sampling slider\n",
    "        \"tfs_z\": 1,  # Tail-free sampling parameter, reduces the impact of low-probability tokens\n",
    "        \"typical_p\": 1,  # Controls how \"typical\" the sampling should be (1 means standard sampling)\n",
    "        \"presence_penalty\": 0.2,  #  penalty for tokens that have appeared at all\n",
    "        \"frequency_penalty\": 0.2,  # penalty based on how frequently tokens have appeared\n",
    "        \"mirostat\": 0,  # \"no Mirostat\" radio option\n",
    "        \"mirostat_tau\": 5,  # Mirostat target complexity (only if mirostat enabled)\n",
    "        \"mirostat_eta\": 0.1,  # Mirostat learning rate (only if mirostat enabled)\n",
    "        \"n_probs\": 0,  # Show Probabilities slider\n",
    "        \"min_keep\": 0,  # Mkeep minimum number of candidates per sampling\n",
    "        \"stop\": [\"#END#\"],\n",
    "        \"stream\": True,\n",
    "        \"prompt\": prompt,\n",
    "        \"cache_prompt\": False,\n",
    "        \"slot_id\": 0\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Accept': 'text/event-stream',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"Sending request...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = requests.post(\n",
    "            'http://127.0.0.1:8080/completion',\n",
    "            json=data,\n",
    "            headers=headers,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        print(\"Receiving response...\")\n",
    "        full_response = \"\"\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                decoded_line = line.decode('utf-8')\n",
    "                if decoded_line.startswith('data: '):\n",
    "                    text = decoded_line[6:]  # Remove 'data: ' prefix\n",
    "                    if text != '[DONE]':\n",
    "                        try:\n",
    "                            json_response = json.loads(text)\n",
    "                            if 'content' in json_response:\n",
    "                                content = json_response['content']\n",
    "                                full_response += content\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(\"Failed to parse JSON:\", text)\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "\n",
    "        print(f\"\\n-------------------\")\n",
    "        print(f\"Total time: {total_time:.2f} seconds\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        \n",
    "    return full_response\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:36:29.291681Z",
     "start_time": "2024-11-10T21:36:03.036154Z"
    }
   },
   "cell_type": "code",
   "source": "out_response = generate_with_llamafile_api(prompt)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request...\n",
      "Receiving response...\n",
      "\n",
      "-------------------\n",
      "Total time: 26.25 seconds\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T21:58:18.179491Z",
     "start_time": "2024-11-10T21:58:18.173802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def replace_references(text, ref_map):\n",
    "    def ref_replacer(match):\n",
    "        ref_name = re.findall(r'<ref name=\"[^\"]+\">', match.group(0))[0]\n",
    "        replacement = ref_map[ref_name]\n",
    "        return replacement\n",
    "\n",
    "    updated_text = re.sub(r'<ref name=\"[^\"]+\">[^<]+</ref>', ref_replacer, text)\n",
    "    return updated_text\n",
    "\n",
    "\n",
    "def return_span(number=1):\n",
    "    return f\"\"\"<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">{number}</span>\"\"\"\n",
    "\n",
    "\n",
    "def convert_input_msg_to_html(answer):\n",
    "    pattern = r'###\\s*Answer\\s*###'\n",
    "    match = re.search(pattern, answer)\n",
    "    start_answer = match.end()\n",
    "    end_answer = answer.find(\"#END#\") if answer.find(\"###\") == -1 else len(answer)\n",
    "    answer = answer[start_answer:end_answer]\n",
    "    references = re.findall(r'<ref name=\"[^\"]+\">', answer)\n",
    "    print(references)\n",
    "    ref_map = {}\n",
    "    reference_count = 1\n",
    "    for ref in references:\n",
    "        if ref not in ref_map:\n",
    "            ref_map[ref] = return_span(reference_count)\n",
    "            reference_count += 1\n",
    "    updated_text = replace_references(answer, ref_map)\n",
    "    return updated_text\n",
    "\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "out = convert_input_msg_to_html(out_response)          \n",
    "HTML(out)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<ref name=\"7b3a9c2d4e8f5g1h\">', '<ref name=\"7b3a9c2d4e8f5g1h\">', '<ref name=\"9d4e2f7c8b5a3h1i\">', '<ref name=\"9d4e2f7c8b5a3h1i\">']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "\n",
       "A transformer is a type of neural network model designed for sequence-to-sequence tasks, such as machine translation and language modeling. It was introduced by Vaswani et al. in 2017 and has since become a cornerstone in the field of natural language processing (NLP).\n",
       "\n",
       "Transformers are capable of generalizing well to various tasks, as evidenced by experiments on English constituency parsing. In a study comparing different models on the Wall Street Journal portion of the Penn Treebank, it was found that a 4-layer transformer outperformed other models, including recurrent neural network (RNN) models, when trained on a small dataset of approximately 40,000 sentences<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">1</span>. Additionally, when trained in a semi-supervised setting using a large corpus, the transformer achieved better results than previous models<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">1</span>.\n",
       "\n",
       "In the context of language modeling, transformers have been shown to act as unsupervised multitask learners. P´erez and his colleagues discovered that unicorns, who were believed to be descendants of a lost alien race, spoke English with a distinct dialect, indicating a possible evolution in their social organization<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">2</span>. This finding highlights the versatility of transformers in tasks where language modeling is crucial<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">2</span>.\n",
       "\n",
       "In summary, transformers are powerful models that exhibit excellent generalization capabilities across different NLP tasks, making them a key innovation in the field. Their ability to perform well on small datasets and in semi-supervised settings sets them apart from other models, making them highly desirable for practical applications in NLP."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T23:20:17.092121Z",
     "start_time": "2024-11-10T23:20:17.087287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = \"\"\"\n",
    "The query pertains to understanding the role of digital tools in enhancing student engagement and motivation during online learning. To address this, we can draw upon several references that provide comprehensive insights into this topic.\n",
    "\n",
    "Firstly, the article by **7b3a9c2d4e8f5g1h** discusses how digital tools can be effectively used to improve student engagement and motivation in online learning environments. It highlights that incorporating interactive elements such as quizzes, polls, and real-time feedback mechanisms can significantly enhance student engagement. The article also notes that providing personalized content and scheduling regular breaks can further boost motivation and reduce burnout among students<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">1</span>.\n",
    "\n",
    "Another reference, **6c7a8b9c10d11e12f**, elaborates on the importance of creating a supportive and interactive learning environment. It suggests that fostering a community among students through group discussions, virtual coffee breaks, and peer mentoring can significantly improve motivation and reduce feelings of isolation during online learning. This article also emphasizes the role of timely and effective communication in maintaining a positive learning experience<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">2</span>.\n",
    "\n",
    "The blog post by **4e5f6g7h8i9j** provides additional context on the practical implementation of these strategies. It shares examples of successful digital tools and practices that have been used in various online learning environments. This personal account can offer practical tips and anecdotes that can help readers visualize how these strategies might be applied in their own teaching contexts<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">3</span>.\n",
    "\n",
    "Lastly, the article by **2c3d4e5f6g7h** provides a broader perspective on the impact of digital tools on student motivation. It discusses how technology can both enhance and detract from student engagement, depending on how it is used. The article recommends a balanced approach where digital tools are used to supplement traditional teaching methods rather than replace them entirely. This ensures that students do not become reliant on technology alone and develop critical thinking skills that are essential for long-term success<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">4</span>.\n",
    "\n",
    "In summary, the use of digital tools in online learning can significantly enhance student engagement and motivation if used effectively. Strategies such as incorporating interactive elements, fostering a supportive community, and maintaining effective communication are crucial for creating a positive learning environment.\n",
    "\"\"\"\n",
    "HTML(out)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "The query pertains to understanding the role of digital tools in enhancing student engagement and motivation during online learning. To address this, we can draw upon several references that provide comprehensive insights into this topic.\n",
       "\n",
       "Firstly, the article by **7b3a9c2d4e8f5g1h** discusses how digital tools can be effectively used to improve student engagement and motivation in online learning environments. It highlights that incorporating interactive elements such as quizzes, polls, and real-time feedback mechanisms can significantly enhance student engagement. The article also notes that providing personalized content and scheduling regular breaks can further boost motivation and reduce burnout among students<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">1</span>.\n",
       "\n",
       "Another reference, **6c7a8b9c10d11e12f**, elaborates on the importance of creating a supportive and interactive learning environment. It suggests that fostering a community among students through group discussions, virtual coffee breaks, and peer mentoring can significantly improve motivation and reduce feelings of isolation during online learning. This article also emphasizes the role of timely and effective communication in maintaining a positive learning experience<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">2</span>.\n",
       "\n",
       "The blog post by **4e5f6g7h8i9j** provides additional context on the practical implementation of these strategies. It shares examples of successful digital tools and practices that have been used in various online learning environments. This personal account can offer practical tips and anecdotes that can help readers visualize how these strategies might be applied in their own teaching contexts<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">3</span>.\n",
       "\n",
       "Lastly, the article by **2c3d4e5f6g7h** provides a broader perspective on the impact of digital tools on student motivation. It discusses how technology can both enhance and detract from student engagement, depending on how it is used. The article recommends a balanced approach where digital tools are used to supplement traditional teaching methods rather than replace them entirely. This ensures that students do not become reliant on technology alone and develop critical thinking skills that are essential for long-term success<span style=\"border: 1px solid #007bff; padding: 2px; border-radius: 3px; background-color: #e7f3ff; color: #007bff; font-size: 12px;\">4</span>.\n",
       "\n",
       "In summary, the use of digital tools in online learning can significantly enhance student engagement and motivation if used effectively. Strategies such as incorporating interactive elements, fostering a supportive community, and maintaining effective communication are crucial for creating a positive learning environment.\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "74acd1ba31504731ae5243331213f143": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_477e4aecd847459bb5c3cd8d9375eff2",
       "IPY_MODEL_aa4fbb4a43f3481e81689fd268a8ce32",
       "IPY_MODEL_7938db68989144c9a9c5b7a584ae5647"
      ],
      "layout": "IPY_MODEL_cdc727d124a74a8189b425f66ce7d98a"
     }
    },
    "477e4aecd847459bb5c3cd8d9375eff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e766f31c12d9458bb96501c4c1ff5bfb",
      "placeholder": "​",
      "style": "IPY_MODEL_c169237169e841d1bb58a1feb2c2ce55",
      "value": ""
     }
    },
    "aa4fbb4a43f3481e81689fd268a8ce32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81f28f0a406c4cf2a801a1b8f92fa5c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4d5ce7b5eda4445a3da4683a3081d8f",
      "value": 1
     }
    },
    "7938db68989144c9a9c5b7a584ae5647": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3de6222b71de463283c94fdb82b5a5a0",
      "placeholder": "​",
      "style": "IPY_MODEL_89f3fd1d549b462f94c8fb2f6060bfe4",
      "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:39&lt;00:00, 39.17s/it]\n"
     }
    },
    "cdc727d124a74a8189b425f66ce7d98a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e766f31c12d9458bb96501c4c1ff5bfb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c169237169e841d1bb58a1feb2c2ce55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81f28f0a406c4cf2a801a1b8f92fa5c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4d5ce7b5eda4445a3da4683a3081d8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3de6222b71de463283c94fdb82b5a5a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f3fd1d549b462f94c8fb2f6060bfe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
